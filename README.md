# ğŸš€ AgentFoundry  
*A multi-agent Agentic RAG framework with MCP server integration*  

---

## ğŸ“Œ Overview  
**AgentFoundry** is a developer-facing framework for building **multi-agent systems** that combine:  
- **Agentic RAG (Retrieval-Augmented Generation with agents)** where agents   **plan, decide, and execute retrieval calls** instead of just stuffing context.  
- **MCP (Model Context Protocol) tools** for interacting with external environments 

The goal is to provide a **minimal but extensible** framework for experimenting with **Agentic RAG + MCP integration** â€” showing how agents can plan, retrieve, act, and validate.  

---

## ğŸ¯ Key Features
- âœ… **Planner Agent** â€“ breaks down complex tasks into subtasks.  
- âœ… **Worker Agents** â€“ execute subtasks using **RAG** and **MCP tools**.  
- âœ… **Verifier Agent** â€“ validates outputs for correctness.  
- âœ… **Agentic RAG Integration** â€“ dynamic retrieval via agents (Planner & Worker use RAG tool only when needed).
- âœ… **MCP Server Integration** â€“ enables external tools 
- âœ… **Normal Orchestration** â€“ central orchestrator coordinating Planner â†’ Worker â†’ Verifier.  
- âœ… **Extensible** â€“ easily add more tools (APIs, DBs, system commands) via MCP.  
- âœ… **Agent-to-Agent (A2A) Communication** â€“ direct agent communication via shared MessageBus with:
  - **Asynchronous message passing** between agents
  - **Cooperative task execution** with idle detection
  - **Tool-aware agents** that can use MCP and RAG tools dynamically
  - **Real-time interaction** with live user input
  - **Error handling** with timeouts and idle detection
  - **Message Bus** for efficient inter-agent communication

---

## ğŸ—ï¸ Current Status  
âœ”ï¸ **Phase 1:** RAG pipeline working (retriever + Gemini LLM).  
âœ”ï¸ **Phase 2:** Wrapped RAG into a LangChain Tool (`rag_answer_tool`).  
âœ”ï¸ **Phase 3:** Multi-agent flow (Planner, Worker, Verifier) built with LangChain.  
âœ”ï¸ **Phase 4:** MCP server added with tools and integrated with Worker.  
âœ”ï¸ **Phase 5:** A2A communication mode implemented with MessageBus.  

ğŸ”œ **Next planned improvements**:  
- Add more MCP tools.
- Streamlit/CLI interface for developer interaction.  
- Optional scaling with Ray Serve.  

---

### Agent Flow :  

#### Traditional Orchestrator Mode:
1. **Planner**: Breaks into subtasks â†’ (search, read, summarize). Decides that **retrieval from knowledge base may be needed** for context.  
2. **Worker**:  
   - Calls MCP `file_search("*.md")`  
   - Calls MCP `read_file("README.md")`  
   - Dynamically decides to call the **`rag_answer_tool`** to fetch additional context from the vector store.  
   - Combines retrieved knowledge + file content and summarizes using LLM.  
3. **Verifier**: Checks that the retrieved knowledge and summary are consistent and accurate.  
4. **Final Output**: A validated, knowledge-grounded summary of README.md.

#### A2A Network Mode:
1. **User Input**: Direct command via interactive CLI
2. **Planner Agent**: Analyzes request and creates task plan
3. **Message Bus**: Distributes subtasks to Worker agent
4. **Worker Agent**: Executes tasks using available tools:
   - **MCP Tools**: `file_search`, `read_file`, `save_file`
   - **RAG Tool**: Knowledge base retrieval when needed
5. **Verifier Agent**: Validates and refines outputs
6. **Real-time Response**: Live feedback and results to user

**A2A Advantages:**
- **Interactive Development**: Test agent capabilities in real-time
- **Tool Discovery**: Agents dynamically select appropriate tools
- **Error Recovery**: Graceful handling of tool failures and network issues
- **Extensible**: Easy to add new agents and tools to the network 

---

## ğŸ› ï¸ Tech Stack  
- **Python**  
- **LangChain** â€“ agent orchestration  
- **Google Gemini LLM** â€“ reasoning & generation  
- **Chroma / FAISS** â€“ vector store for RAG  
- **FastMCP** â€“ lightweight MCP server  
- **MCP Toolkit for LangChain** â€“ dynamic tool integration  

---

## ğŸ“‚ Project Structure

```text
agentfoundry/
â”œâ”€â”€ MCP/
â”‚   â”œâ”€â”€ MCP_servers.py
â”‚   â””â”€â”€ mcp_tools_adapter.py
â”œâ”€â”€ RAG/
â”‚   â”œâ”€â”€ agentic_rag.py
â”‚   â”œâ”€â”€ load_docs.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ rag_tool.py
â”‚   â””â”€â”€ vector_store.py
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ planner.py
â”‚   â”œâ”€â”€ worker.py
â”‚   â””â”€â”€ verifier.py
â”œâ”€â”€ rag_db/
â”œâ”€â”€ central.py
â”œâ”€â”€ orchestrator.py
â”œâ”€â”€ messaging.py
â”œâ”€â”€ a2a_network.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â””â”€â”€ sample.txt
```


## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/AgentFoundry.git
cd AgentFoundry
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run MCP Server (Tools available on port 8000/stdio)

```bash
python MCP/MCP_servers.py
```

### 4. Run the Orchestrator

```bash
python orchestrator.py
```

### 5. Run the A2A Network

```bash
python a2a_network.py
```

## ğŸ¤ Contribution

AgentFoundry is developer-facing â€” contributions are welcome for:

- Adding new MCP tools
- A2A communication 
- Enhancing scalability & observability

Feel free to open issues or submit pull requests!
